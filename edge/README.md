# Edge Module - Documentaci√≥n

## üìÅ Estructura

```
edge/
‚îú‚îÄ‚îÄ __init__.py         # Package init
‚îú‚îÄ‚îÄ camera.py           # CameraManager (RealSense + c√°mara est√°ndar)
‚îú‚îÄ‚îÄ detector.py         # PersonDetector (YOLOv8)
‚îú‚îÄ‚îÄ tracker.py          # BoTSORT tracker
‚îú‚îÄ‚îÄ gaze.py             # GazeEstimator (atenci√≥n)
‚îú‚îÄ‚îÄ session.py          # SessionManager (sesiones an√≥nimas)
‚îî‚îÄ‚îÄ main.py             # EdgeProcessor (loop principal)
```

## üéØ Componentes

### 1. CameraManager (`camera.py`)
Gestor unificado de fuentes de video con detecci√≥n autom√°tica:

```python
# Modo 1: Archivo de video
camera = CameraManager(video_path="videos/demo.mp4")

# Modo 2: RealSense (auto-detecta)
camera = CameraManager(width=640, height=480, fps=30)

# Modo 3: C√°mara espec√≠fica
camera = CameraManager(camera_id=1)

camera.start()  # Auto-detecta: Video ‚Üí RealSense ‚Üí C√°mara est√°ndar

# Obtener frames
color, depth, depth_rs = camera.get_frames()

# Verificar modo y progreso
print(f"Es live: {camera.is_live}")
print(f"Usa video: {camera.use_video}")
if camera.use_video:
    progress = camera.get_progress()
    print(f"Progreso: {progress['progress_percent']:.1f}%")
```

**Caracter√≠sticas**:
- Prioridad: Video file ‚Üí RealSense ‚Üí C√°mara est√°ndar
- Soporte de formatos: MP4, AVI, MOV, MKV, FLV, WMV
- Seguimiento de progreso para videos
- Estimaci√≥n de distancia 2D cuando no hay depth
- No requiere `pyrealsense2` para funcionar

### 2. PersonDetector (`detector.py`)
Wrapper de YOLOv8 para detecci√≥n de personas:

```python
detector = PersonDetector(model_path="yolov8n.pt")
detections = detector.detect(frame)  # Returns [x1, y1, x2, y2, conf]
```

**Caracter√≠sticas**:
- Solo detecta clase "person" (clase 0 en COCO)
- Warm-up autom√°tico del modelo
- Optimizado para Edge devices

### 3. BoTSORT (`tracker.py`)
Tracker multi-objeto sin Re-ID biom√©trico:

```python
tracker = BoTSORT(max_age=30, min_hits=3, iou_threshold=0.3)
tracks = tracker.update(detections)  # Returns [x1, y1, x2, y2, track_id]
```

**Caracter√≠sticas**:
- Kalman Filter para predicci√≥n de movimiento
- Asociaci√≥n por IoU (no usa features faciales)
- Minimiza ID switches
- Cumple privacidad √©tica

### 4. GazeEstimator (`gaze.py`)
Estimaci√≥n de atenci√≥n sin biometr√≠a:

```python
gaze = GazeEstimator(screen_position=(0, 0, 200))

# Modo 3D (con RealSense)
is_looking = gaze.is_looking_at_screen(person_position=position_3d)

# Modo 2D (sin RealSense)
is_looking = gaze.is_looking_at_screen(
    bbox_center=(cx, cy),
    frame_size=(width, height)
)
```

**Caracter√≠sticas**:
- Funciona con o sin depth data
- Fallback 2D: posici√≥n en el frame
- No usa an√°lisis facial

### 5. SessionManager (`session.py`)
Gesti√≥n de sesiones an√≥nimas:

```python
manager = SessionManager(timeout=3, fps=30)

# Actualizar sesi√≥n
manager.update_session(
    track_id=1,
    is_looking=True,
    distance_cm=200
)

# Obtener sesiones expiradas
expired = manager.get_expired_sessions()
payloads = manager.generate_payloads(expired)
```

**Caracter√≠sticas**:
- IDs temporales en RAM (nunca se transmiten)
- Destrucci√≥n autom√°tica despu√©s del timeout
- Generaci√≥n de payloads an√≥nimos

### 6. EdgeProcessor (`main.py`)
Orquestador principal:

```python
processor = EdgeProcessor()
processor.start()  # Inicia el loop de procesamiento
```

**Pipeline**:
1. Captura frame
2. Detecci√≥n (YOLO)
3. Tracking (BoT-SORT)
4. C√°lculo de posici√≥n/distancia
5. Estimaci√≥n de atenci√≥n
6. Actualizaci√≥n de sesiones
7. Env√≠o de sesiones expiradas al API

## üîÑ Flujo de Datos

```
Video/C√°mara ‚Üí Frame
    ‚Üì
YOLO ‚Üí Detecciones [x1, y1, x2, y2, conf]
    ‚Üì
BoT-SORT ‚Üí Tracks [x1, y1, x2, y2, track_id]
    ‚Üì
[Para cada track]
    ‚îú‚îÄ Depth/2D ‚Üí Distancia
    ‚îú‚îÄ Gaze ‚Üí is_looking
    ‚îî‚îÄ Session ‚Üí update()
    ‚Üì
[Timeout]
    ‚Üì
SessionManager ‚Üí Payload an√≥nimo
    ‚Üì
HTTP ‚Üí API
    ‚Üì
[Si es video: continuar hasta fin]
[Si es live: loop infinito]
```

## ‚öôÔ∏è Configuraci√≥n

### Variables de entorno (`.env`):

```bash
# Device
DEVICE_ID=12
SESSION_TIMEOUT=3
FIRMWARE_VERSION=1.8.2

# Video/Camera (prioridad: VIDEO_PATH ‚Üí RealSense ‚Üí Camera)
VIDEO_PATH=  # Ruta a video file (dejar vac√≠o para c√°mara en vivo)
REALSENSE_WIDTH=640
REALSENSE_HEIGHT=480
REALSENSE_FPS=30
CAMERA_ID=0

# YOLO
YOLO_MODEL_PATH=models/yolov8n.pt
YOLO_CONFIDENCE=0.5

# Tracker
MAX_AGE=30
MIN_HITS=3
IOU_THRESHOLD=0.3

# API
API_URL=http://localhost:8000
API_KEY=your-secret-key
```

## üöÄ Ejecuci√≥n

### Modo b√°sico (c√°mara en vivo):
```bash
python edge/main.py
```

### Procesar archivo de video:
```bash
# Opci√≥n 1: Argumento de l√≠nea de comandos
python edge/main.py --video videos/demo.mp4

# Opci√≥n 2: Script dedicado
python process_video.py videos/demo.mp4

# Opci√≥n 3: Configurar VIDEO_PATH en .env
VIDEO_PATH=videos/demo.mp4
python edge/main.py
```

### Con c√°mara espec√≠fica:
```bash
# En .env
CAMERA_ID=1

# O por l√≠nea de comandos
python edge/main.py --device-id 13
```

### Test de fuentes:
```bash
python test_camera.py
```

### Opciones de l√≠nea de comandos:
```bash
python edge/main.py --help

# Argumentos disponibles:
#   --video PATH        Ruta a archivo de video
#   --device-id ID      ID del dispositivo Edge
```

## üìä M√©tricas de Performance

### Hardware m√≠nimo recomendado:
- **CPU**: Intel i5 o equivalente
- **RAM**: 4GB
- **GPU**: Opcional (mejora FPS)

### FPS esperado:
- YOLOv8n + CPU: ~15-20 FPS
- YOLOv8n + GPU: ~60+ FPS
- YOLOv8s + CPU: ~10-15 FPS
- YOLOv8m + CPU: ~5-8 FPS

### Optimizaciones:
1. Usar modelo m√°s peque√±o (`yolov8n.pt`)
2. Reducir resoluci√≥n (320x240)
3. Reducir FPS (15 fps)
4. Usar TensorRT/OpenVINO (si disponible)

## üîí Privacidad

### ‚úÖ Garant√≠as:
- **No se almacenan im√°genes** en ning√∫n momento
- **No se almacena video**
- **IDs temporales** solo en RAM
- **IDs destruidos** despu√©s del timeout
- **No se transmiten IDs** al API
- **No hay Re-ID** biom√©trico/facial

### ‚úÖ Payload enviado:
```json
{
  "device_id": 12,
  "start_time": "2025-12-09T14:30:00Z",
  "duration_seconds": 14,
  "attention_seconds": 9.4,
  "demographics": {
    "age_group": "unknown",
    "gender_estimation": "unknown",
    "distance_cm": 180
  }
}
```

**Nota**: No incluye im√°genes, track_id, ni datos biom√©tricos.

## üß™ Testing

### Test de c√°mara:
```bash
python test_camera.py
```

### Test de detecci√≥n:
```python
from edge.detector import PersonDetector
import cv2

detector = PersonDetector()
frame = cv2.imread("test.jpg")
detections = detector.detect(frame)
print(f"Detectadas {len(detections)} personas")
```

### Test de sesiones:
```python
from edge.session import SessionManager

manager = SessionManager(timeout=3)
manager.update_session(1, is_looking=True, distance_cm=200)
# Esperar 3+ segundos
expired = manager.get_expired_sessions()
payloads = manager.generate_payloads(expired)
```

## üìù Logs

El sistema genera logs detallados:

```
2025-12-09 14:30:00 | INFO | Inicializando Edge Processor...
2025-12-09 14:30:01 | INFO | ‚úì Modelo YOLO cargado: models/yolov8n.pt
2025-12-09 14:30:02 | INFO | ‚úì Usando c√°mara est√°ndar (sin depth)
2025-12-09 14:30:02 | INFO | ‚úì Edge Processor inicializado
2025-12-09 14:30:02 | INFO | üöÄ Edge Processor iniciado - Procesando...
2025-12-09 14:30:12 | INFO | üìä Frame 300 | Activas: 2 | Completadas: 5
```

## üêõ Troubleshooting

Ver [CAMERA_SYSTEM.md](../docs/CAMERA_SYSTEM.md) para gu√≠a completa.

### Problemas comunes:

1. **C√°mara no disponible**: Verificar CAMERA_ID en `.env`
2. **YOLO lento**: Usar modelo m√°s peque√±o o reducir resoluci√≥n
3. **Muchos ID switches**: Aumentar MAX_AGE, reducir MIN_HITS
4. **Sesiones muy cortas**: Aumentar SESSION_TIMEOUT
